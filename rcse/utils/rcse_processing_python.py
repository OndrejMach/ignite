from airflow.operators.bash_operator import BashOperatorfrom datetime import datetimefrom airflow import DAGfrom datetime import datedefault_args = {    'owner': 'kr_prod_airflow_operation_ewhr',    'run_as_user': 'talend_ewhr',    'start_date': datetime(2020, 2, 18),    'retries': 0}dag = DAG(    dag_id='RCSE_ETL_processing_python',    default_args=default_args,    description='RCSE_ETL_processing_python',    schedule_interval='@once',    start_date=datetime(2017, 3, 20),    catchup=False)processing_date = "20200801" #date.today().strftime("%Y%m%d")input_folder="/user/talend_ewhr/rcse/input/"stage_folder="/user/talend_ewhr/rcse/stage/"output_folder="/user/talend_ewhr/rcse/out/"input_data = "/data/input/ewhr/archive/rcse/"app_home = "/home/talend_ewhr/rcse_spark/"encoder  = "/home/talend_ewhr/rcse_spark/a.out"archive_folder = "/data/input/ewhr/archive/rcse/"kinit_command = "/opt/shared/runtime/anaconda3/airconda/bin/kinit talend_ewhr@CDRS.TELEKOM.DE -k -t /home/talend_ewhr/talend_ewhr.keytab"log_options= "-Dlog4j.configuration=file:{}log4j.properties".format(app_home)params= "-Dconfig.processingDate={} ".format(processing_date) + \        "-Dconfig.inputFilesPath={}TMD_* ".format(input_folder)  + \        "-Dconfig.master=yarn " + \        "-Dconfig.stageFiles.stagePath={} ".format(stage_folder) + \        "-Dconfig.stageFiles.imsisEncodedPath={}imsi_encoded.csv ".format(input_folder)+ \        "-Dconfig.stageFiles.msisdnsEncodedPath={}msisdn_encoded.csv ".format(input_folder)+ \        "-Dconfig.outputs.outputPath={} -Dlog4j.configuration=file:{}log4j.properties".format(output_folder,app_home )spark_submit_template =kinit_command+" && "+ "/usr/bin/spark2-submit --master yarn --queue root.ewhr_technical --deploy-mode client " + \                       "--driver-java-options=\"{}\" --conf spark.executor.extraJavaOptions=\"{}\" --files {}/log4j.properties ".format(params,log_options,app_home) + \                       "--class com.tmobile.sit.ignite.rcse.Application {}ignite-1.0-all.jar ".format(app_home)export_msisdns = BashOperator(task_id='export_msisdns',                              bash_command='cat {}/TMD_*{}.csv.gz|gunzip |cut -f 2 -d \'|\'|sort -u >{}msisdn.csv'.format(input_data, processing_date, app_home),                              queue='EVL_Queue',                              dag=dag)export_imsis = BashOperator(task_id='export_imsis',                            bash_command='cat {}/TMD_*{}.csv.gz|gunzip |cut -f 3 -d \'|\'|sort -u >{}imsi.csv'.format(input_data, processing_date, app_home),                            queue='EVL_Queue',                            dag=dag)encode_msisdns = BashOperator(task_id='encode_msisdns',                              bash_command='{} {}/msisdn.csv > {}msisdn_encoded.csv'.format(encoder, app_home, app_home),                              queue='EVL_Queue',                              dag=dag)encode_imsis = BashOperator(task_id='encode_imsis',                            bash_command='{} {}/imsi.csv > {}imsi_encoded.csv'.format(encoder, app_home, app_home),                            queue='EVL_Queue',                            dag=dag)hdfs_put = BashOperator(task_id='hdfs_put',                        bash_command='{} && hdfs dfs -rm {}/* && hdfs dfs -put {}TMD_*{}* {}msisdn_encoded.csv {}imsi_encoded.csv {} && hdfs dfs -ls {}'.format(kinit_command, input_folder, archive_folder, processing_date,app_home,app_home, input_folder,input_folder ),                        queue='EVL_Queue',                        dag=dag)input_processing = BashOperator(task_id='input_processing',                                bash_command=spark_submit_template + "terminalD",                                queue='EVL_Queue',                                dag=dag)events_processing = BashOperator(task_id='events_processing',                                 bash_command=spark_submit_template + "events",                                 queue='EVL_Queue',                                 dag=dag)conf_processing = BashOperator(task_id='conf_processing',                               bash_command=spark_submit_template + "conf",                               queue='EVL_Queue',                               dag=dag)activeUsers_processing = BashOperator(task_id='activeUsers_processing',                                      bash_command=spark_submit_template + "activeUsers",                                      queue='EVL_Queue',                                      dag=dag)aggregates_processing = BashOperator(task_id='aggregates_processing',                                     bash_command=spark_submit_template + "aggregates",                                     queue='EVL_Queue',                                     dag=dag)output_processing = BashOperator(task_id='output_processing',                                 bash_command=spark_submit_template + "output",                                 queue='EVL_Queue',                                 dag=dag)export_msisdns >> export_imsis >>encode_msisdns >> encode_imsis >> hdfs_put >> input_processing >> events_processing >> conf_processing >> activeUsers_processing >> aggregates_processing >> output_processing